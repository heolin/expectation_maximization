{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.60615269069 -1.40204271809\n",
      "-3.21113625277 -4.62888671261\n",
      "-2.11252396411 -3.12480931583\n",
      "-2.19393935559 -1.58436427488\n",
      "-1.5371598192 -2.14398006282\n",
      "-2.40343288476 -1.53614679922\n",
      "-1.99004088758 -3.44989556572\n",
      "-1.39602248873 -2.27409197595\n",
      "-3.49581343948 -2.04674216301\n",
      "-1.32525223364 -1.62153652994\n",
      "-2.77865477409 -1.49890204074\n",
      "-1.7108648207 -3.61048491487\n",
      "-1.2804459109 -2.38522279819\n",
      "-4.03463481786 -1.96003887763\n",
      "-1.37327514487 -1.68320882528\n",
      "-3.09697527159 -1.45136128826\n",
      "-1.53339068708 -3.88302217756\n",
      "-1.22692043506 -2.57774055709\n",
      "-4.47690397314 -1.83247862136\n",
      "-1.44369832681 -1.79570708038\n",
      "-3.33571628361 -1.4260677084\n",
      "-1.42574324537 -4.09814488079\n",
      "-1.20587010678 -2.73275918954\n",
      "-4.8022420986 -1.74708097073\n",
      "-1.50924511196 -1.89062164206\n",
      "-3.47093524662 -1.41587583076\n",
      "-1.37258753855 -4.2218332585\n",
      "-1.19980806742 -2.82297750342\n",
      "-4.98455472906 -1.70341902925\n",
      "-1.55027674005 -1.9473698921\n",
      "-3.53291557804 -1.41207941873\n",
      "-1.34989455846 -4.28043665699\n",
      "-1.19828341521 -2.86598094928\n",
      "-5.06770338836 -1.68402266459\n",
      "-1.56992041572 -1.97477338533\n",
      "-3.55822784787 -1.41064467011\n",
      "-1.34091198337 -4.30562037729\n",
      "-1.19787455135 -2.88451005235\n",
      "-5.10158936941 -1.67593329874\n",
      "-1.57808526309 -1.98664787117\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#### E-M Coin Toss Example as given in the EM tutorial paper by Do and Batzoglou* #### \n",
    "\n",
    "def get_mn_log_likelihood(obs,probs):\n",
    "    \"\"\" Return the (log)likelihood of obs, given the probs\"\"\"\n",
    "    # Multinomial Distribution Log PMF\n",
    "    # ln (pdf)      =             multinomial coeff            *   product of probabilities\n",
    "    # ln[f(x|n, p)] = [ln(n!) - (ln(x1!)+ln(x2!)+...+ln(xk!))] + [x1*ln(p1)+x2*ln(p2)+...+xk*ln(pk)]     \n",
    "\n",
    "    multinomial_coeff_denom= 0\n",
    "    prod_probs = 0\n",
    "    for x in range(0,len(obs)): # loop through state counts in each observation\n",
    "        multinomial_coeff_denom = multinomial_coeff_denom + math.log(math.factorial(obs[x]))\n",
    "        prod_probs = prod_probs + obs[x]*math.log(probs[x])\n",
    "\n",
    "    multinomial_coeff = math.log(math.factorial(sum(obs))) -  multinomial_coeff_denom\n",
    "    likelihood = multinomial_coeff + prod_probs\n",
    "    return likelihood\n",
    "\n",
    "# 1st:  Coin B, {HTTTHHTHTH}, 5H,5T\n",
    "# 2nd:  Coin A, {HHHHTHHHHH}, 9H,1T\n",
    "# 3rd:  Coin A, {HTHHHHHTHH}, 8H,2T\n",
    "# 4th:  Coin B, {HTHTTTHHTT}, 4H,6T\n",
    "# 5th:  Coin A, {THHHTHHHTH}, 7H,3T\n",
    "# so, from MLE: pA(heads) = 0.80 and pB(heads)=0.45\n",
    "\n",
    "# represent the experiments\n",
    "head_counts = np.array([5,9,8,4,7])\n",
    "tail_counts = 10-head_counts\n",
    "experiments = zip(head_counts,tail_counts)\n",
    "\n",
    "# initialise the pA(heads) and pB(heads)\n",
    "pA_heads = np.zeros(100); pA_heads[0] = 0.60\n",
    "pB_heads = np.zeros(100); pB_heads[0] = 0.50\n",
    "\n",
    "\n",
    "# E-M begins!\n",
    "delta = 0.001  \n",
    "j = 0 # iteration counter\n",
    "improvement = float('inf')\n",
    "while (improvement>delta):\n",
    "    expectation_A = np.zeros((5,2), dtype=float) \n",
    "    expectation_B = np.zeros((5,2), dtype=float)\n",
    "    for i in range(0,len(experiments)):\n",
    "        e = experiments[i] # i'th experiment\n",
    "        ll_A = get_mn_log_likelihood(e,np.array([pA_heads[j],1-pA_heads[j]])) # loglikelihood of e given coin A\n",
    "        ll_B = get_mn_log_likelihood(e,np.array([pB_heads[j],1-pB_heads[j]])) # loglikelihood of e given coin B\n",
    "        print ll_A, ll_B\n",
    "        weightA = math.exp(ll_A) / ( math.exp(ll_A) + math.exp(ll_B) ) # corresponding weight of A proportional to likelihood of A \n",
    "        weightB = math.exp(ll_B) / ( math.exp(ll_A) + math.exp(ll_B) ) # corresponding weight of B proportional to likelihood of B                            \n",
    "\n",
    "        expectation_A[i] = np.dot(weightA, e) \n",
    "        expectation_B[i] = np.dot(weightB, e)\n",
    "    \n",
    "    pA_heads[j+1] = sum(expectation_A)[0] / sum(sum(expectation_A)); \n",
    "    pB_heads[j+1] = sum(expectation_B)[0] / sum(sum(expectation_B)); \n",
    "\n",
    "    improvement = max( abs(np.array([pA_heads[j+1],pB_heads[j+1]]) - np.array([pA_heads[j],pB_heads[j]]) ))\n",
    "    j = j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
